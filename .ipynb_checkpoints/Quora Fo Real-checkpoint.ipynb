{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (404290, 6)\n",
      "Test:  (2345796, 3)\n"
     ]
    }
   ],
   "source": [
    "#Let's start by importing our csv's as DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print('Training: ', df_train.shape)\n",
    "print('Test: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print info about our data frame\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 226657 to 386555\n",
      "Data columns (total 6 columns):\n",
      "id              20000 non-null int64\n",
      "qid1            20000 non-null int64\n",
      "qid2            20000 non-null int64\n",
      "question1       20000 non-null object\n",
      "question2       20000 non-null object\n",
      "is_duplicate    20000 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#It's a good idea to take only a small sample of the data\n",
    "#We can remove this block when we are ready to test the whole dataset\n",
    "sample_size = 10000\n",
    "true_questions = df_train[df_train.is_duplicate == 1]\n",
    "false_questions = df_train[df_train.is_duplicate == 0]\n",
    "\n",
    "df_train = pd.concat([true_questions.sample(sample_size), false_questions.sample(sample_size)])\n",
    "df_train = df_train.sample(df_train.shape[0])\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's get started extracting some simple (and possible insightful) features\n",
    "\n",
    "(Side note): When using the axis parameter for apply method.\n",
    "axis : {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "0 or ‘index’: apply function to each column\n",
    "1 or ‘columns’: apply function to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['q1_feat_length'] = df_train['question1'].apply(lambda x: len(str(x)))\n",
    "df_train['q2_feat_length'] = df_train['question2'].apply(lambda x: len(str(x)))\n",
    "\n",
    "df_train['feat_length_diff'] = df_train['q1_feat_length'] - df_train['q2_feat_length']\n",
    "\n",
    "df_train['q1_feat_num_chars'] = df_train['question1'].apply(lambda x: len(''.join(set(str(x).replace(' ','')))))\n",
    "df_train['q2_feat_num_chars'] = df_train['question2'].apply(lambda x: len(''.join(set(str(x).replace(' ','')))))\n",
    "\n",
    "df_train['q1_feat_num_words'] = df_train['question1'].apply(lambda x: len(str(x).split()))\n",
    "df_train['q2_feat_num_words'] = df_train['question2'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "df_train['feat_num_matching_words'] = df_train.apply(lambda x: len(set(str(x['question1']).lower().split()) \\\n",
    "                                                                   .intersection(str(x['question2']).lower().split())), axis=1)\n",
    "\n",
    "#Now we will use an awesome string-matching library called FuzzyWuzzy. http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n",
    "#It has a lot of useful helper methods for predicting sentence matching\n",
    "#We will use QRatio: Q stands for quick. Quick ratio comparison between two strings.\n",
    "#Returns a similarity ratio from 0-100\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "df_train['feat_qratio'] = df_train.apply(lambda x: fuzz.QRatio(str(x['question1']),str(x['question2'])), axis=1)\n",
    "\n",
    "#WRatio: Return a measure of the sequences' similarity between 0 and 100, using different algorithms.\n",
    "df_train['feat_wratio'] = df_train.apply(lambda x: fuzz.WRatio(str(x['question1']), str(x['question2'])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question1 Progress:   0%| | 1/20000 [02:05<698:57:19, 125.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\G4M3M4ST3R\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question1 Progress:   0%|         | 0/20000 [00:00<?, ?it/s]\n",
      "\n",
      "Question1 Progress:  34%|▎| 6732/20000 [00:02<00:03, 3365.18it/s]\n",
      "\n",
      "Question1 Progress:  67%|▋| 13413/20000 [00:04<00:01, 3357.70it/s]\n",
      "\n",
      "Question1 Progress: 100%|█| 20000/20000 [00:05<00:00, 3356.81it/s]\n",
      "\n",
      "Question2 Progress:   0%|         | 0/20000 [00:00<?, ?it/s]\n",
      "\n",
      "Question2 Progress:  33%|▎| 6667/20000 [00:02<00:04, 3332.69it/s]\n",
      "\n",
      "Question2 Progress:  66%|▋| 13297/20000 [00:04<00:02, 3327.13it/s]\n",
      "\n",
      "Question2 Progress:  99%|▉| 19806/20000 [00:06<00:00, 3304.76it/s]\n",
      "\n",
      "Question2 Progress: 100%|█| 20000/20000 [00:06<00:00, 3296.82it/s]"
     ]
    }
   ],
   "source": [
    "#Firstly, we should clean the data. This will give our model the best chance to identify duplicates accurately. \n",
    "#This means removing ambiguous stop words.\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from tqdm import tqdm #for progressbar\n",
    "\n",
    "def extractStopWords(question):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = question.split()\n",
    "    meaningful_words = [w.lower() for w in words if not w in stops]\n",
    "    return meaningful_words      \n",
    "        \n",
    "tqdm.pandas(mininterval=2,ncols=60, desc='Question1 Progress')\n",
    "df_train[\"cleaned_q1\"] = df_train.question1.progress_apply(extractStopWords)\n",
    "\n",
    "tqdm.pandas(mininterval=2,ncols=60, desc='Question2 Progress')\n",
    "df_train[\"cleaned_q2\"] = df_train.question2.progress_apply(extractStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Training Complete!\n",
      "Number of tokens in Word2Vec: 6668\n"
     ]
    }
   ],
   "source": [
    "#Now we can finally begin constructing our CNN\n",
    "#Let's first create word vectors for our questions\n",
    "import gensim\n",
    "\n",
    "questions = list(df_train['cleaned_q1']) + list(df_train['cleaned_q2']) \n",
    "\n",
    "print (\"Training model...\")\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "df_train['wmd'] = df_train.apply(lambda x: wmd(x['question1'], x['question2']), axis=1)\n",
    "print (\"Training Complete!\")\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "\n",
    "# creta a dict \n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "print (\"Number of tokens in Word2Vec:\", len(w2v.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('60', 0.986575722694397),\n",
       " ('food,', 0.9854674339294434),\n",
       " ('ages', 0.9844881892204285),\n",
       " ('weak', 0.983527660369873),\n",
       " ('worried', 0.9834195971488953),\n",
       " ('overweight', 0.9833500385284424),\n",
       " ('hand?', 0.9832106828689575),\n",
       " ('emma', 0.9830905795097351),\n",
       " ('persons', 0.9826271533966064),\n",
       " ('walk', 0.9822831749916077)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"sugar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
